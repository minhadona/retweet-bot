{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    Bot by: @minhadona\n",
    "    First Release: 1 jan 2021 \n",
    "    big text letters font generator: https://fsymbols.com/generators/tarty/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    checking_folders = checks_if_necessary_folders_exist_otherwise_create_them()\n",
    "    checking_files = checks_if_necessary_files_exist_otherwise_create_them()\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # -------- giving chance to a first-time user to change the bot rules --------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    \n",
    "    if type(checking_files) is str or type(checking_folders) is list:\n",
    "        logging(f'main(): checking return: {checking_files}')\n",
    "        want_to_insert_rules = pymsgbox.confirm('HEY ! it looks like this is your first time here! Would you like to insert retweeting rules here?\\nï½™ï½ï½•ã€€ï½ƒï½ï½ã€€ï½ï½Œï½—ï½ï½™ï½“ã€€ï½•ï½ï½„ï½ï½”ï½…ã€€ï½”ï½ˆï½…ï½ã€€ï½ï½ã€€bot_files/controls/attributes.json \\nPLEASE, NOTICE THAT if you click NO (dont insert the rules now), bot will start by using the initial template! Check the json file NOW to see the standard assignments we will begin with', 'INSERT RULES NOW?', [\"Yes\", \"No, keep standard attributes\"])\n",
    "        if want_to_insert_rules == 'Yes': \n",
    "            receive_information_overwrite_json(json=\"attributes\")\n",
    "            \n",
    "    elif type(checking_folders) is str:\n",
    "        logging(f'main(): checking return FOLDERS: {checking_folders}')\n",
    "        raise TypeError('Error: necessary FOLDER structure cannot be created or validated')\n",
    "    \n",
    "    elif type(checking_files) is int:\n",
    "        logging(f'main(): checking return FILES: {checking_files}')\n",
    "        raise TypeError('Error: necessary FILES structure cannot be created or validated')\n",
    "        \n",
    "    elif type(checking_files) is dict:\n",
    "        logging('main(): ok, all files were validated, we may start the bot!!!!')\n",
    "\n",
    "    logging(render('begin of lap', font=\"slick\", background='transparent'))\n",
    "        \n",
    "    credentials_json = useful_variables.credentials_json\n",
    "    attributes_json = useful_variables.attributes_json\n",
    "    control_json = useful_variables.control_json\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ---------------- populating dictionary with API credentials from json ------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "\n",
    "    with open(credentials_json) as credentials_file:\n",
    "        credentials = json.load(credentials_file)\n",
    "        #logging('credential value: '+ str(credentials))\n",
    "                             \n",
    "    pymsgbox.alert(\"Starting bot!\\n\\nYou can see what we're doing by reading today's logs on bot_files//logs folder!\", 'Starting bot',timeout=8000)\n",
    "    \n",
    "\n",
    "    try: \n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ------------------- authenticating by using API credentials ----------------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "        api = authenticating(credentials) # even if authentication fails, twitter unfortunately still returns an api object\n",
    "                                          # an exception is only raised on tweepy.Cursor, and to query our tweets \n",
    "                                          # we have an unavoidable rather long way to go through\n",
    "                                          # we need to seek the attributes/rules we want BEFORE trying to request\n",
    "                                          # that's why we have this huge code-block inside this 'try' statement :/\n",
    "        \n",
    "        with open(attributes_json) as json_file:\n",
    "            dict_attributes_info = json.load(json_file)\n",
    "            \n",
    "        words = dict_attributes_info[\"words_to_search\"]\n",
    "        words_str = str(words).replace('[','').replace(']','').replace('\\'',\"\") \n",
    "        logging(f\"main(): these are the words we're gonna look for: {words_str}\")\n",
    "        pymsgbox.alert(f\"these are the words we're gonna look for: {words_str}\",\"YOUR WISH IS MY COMMAND\",timeout= 6500)\n",
    "        \n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # ---- for every word from attributes.json, a while will retrieve N tweets (default is 1800) ----\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    \n",
    "        try:\n",
    "            tweet_qtd_for_lap = int(dict_attributes_info[\"amount_of_tweets_to_retrieve_for_every_word\"]) \n",
    "                # cast to int just in case someone put some \" on json \n",
    "        except ValueError:\n",
    "                # if a letter was inserted, we can't go on \n",
    "            logging(f'main(): amount of tweets is not convertible to integer, someone inserted a string value on our key...')\n",
    "            liveshow('something went wrong reading HOW MANY tweets you want to retrieve per word in attributes.json, please be sure you inserted a NUMBER and not a letter on amount_of_tweets_to_retrieve_for_every_word key')\n",
    "            raise Exception('if we dont know how many tweets to query, we cant start our bot, sorry')\n",
    "            \n",
    "        logging(f'main(): amount of tweets that will be retrieved for every word: {tweet_qtd_for_lap}')\n",
    "        \n",
    "        for searched_word in words: \n",
    "    \n",
    "            for tweet in tweepy.Cursor(api.search, tweet_mode='extended', q = searched_word).items(tweet_qtd_for_lap):\n",
    "    \n",
    "                dict_tweets_info = {\n",
    "                \"created_at\": [],\n",
    "                \"tweet_ID\": [],\n",
    "                \"user\": [],\n",
    "                \"tweet_content\": [],\n",
    "                \"place\": [],\n",
    "                \"language\": [],\n",
    "                \"source\": [] \n",
    "            }\n",
    "            # --------------------------------------------------------------------------------------\n",
    "            # ---------------- check if we transpassed our daily limit of retweeting ---------------\n",
    "            # --------------------------------------------------------------------------------------\n",
    "            \n",
    "            logging('main(): checking if we reached our daily limit of successful retweets')\n",
    "            with open(control_json) as json_file:\n",
    "                tweets_status = json.load(json_file)\n",
    "                \n",
    "                today_date = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "    \n",
    "                if tweets_status[\"amount_of_tweets\"] == 999 and tweets_status['current_date'] == today_date: \n",
    "                    pymsgbox.alert(\"WE CANT RETWEET ANYMORE, SAFE DAILY LIMIT IS 1000 RETWEETS\",'s o r r y',timeout=8000)\n",
    "                    logging('main(): we ve reached 1000 successefully retweets today, we re quiting')\n",
    "                    raise Exception('DAILY LIMIT REACHED, CANT RETWEET MORE THAN 1000 TWEETS')\n",
    "                else:\n",
    "                    logging('main(): ok we re below the limits for successful retweets') \n",
    "                    logging(f'main(): we have successfully retweeted {tweets_status[\"amount_of_tweets\"]} tweets until now')\n",
    "                        \n",
    "            # --------------------------------------------------------------------------------------\n",
    "            # ------- check if tweet is within the rules (language restrictions, content etc) ------\n",
    "            # --------------------------------------------------------------------------------------              \n",
    "            \n",
    "                valid_tweet = validate_and_retweet_tweet(api,\n",
    "                                                         tweet,\n",
    "                                                         dict_tweets_info,\n",
    "                                                         dict_attributes_info,\n",
    "                                                         searched_word)\n",
    "\n",
    "            # --------------------------------------------------------------------------------------\n",
    "            # ------- if tweet is valid, we export tweet's data to csv file of today ---------------\n",
    "            # -------------------------------------------------------------------------------------- \n",
    "            \n",
    "                if type(valid_tweet) is dict:\n",
    "                    logging('main(): VALID TWEET !!!!! Ok, we may export our data now')\n",
    "                    export_infos_to_csv(valid_tweet)\n",
    "                    write_json_and_updates_value(control_json,\n",
    "                                                 increment_success_amount = True)\n",
    "                    \n",
    "            # --------------------------------------------------------------------------------------\n",
    "            # - if tweet is invalid, we log the reason and increment tweet counter (control json) --\n",
    "            # -------------------------------------------------------------------------------------- \n",
    "            \n",
    "                elif type(valid_tweet) is int:\n",
    "                    logging(f'main(): Tweet is not valid, analyzing return:: {valid_tweet}')\n",
    "                    cases={\n",
    "                        -1 : \"didn't found the searched_word on tweet.text it self\",\n",
    "                        -2 : \"forbidden/invalid language (japanese, korean, arabic etc problems to recognize the searched word)\",\n",
    "                        -3 : \"you have already retweeted this Tweet\",\n",
    "                        -4 : \"RateLimitError\",\n",
    "                        -5 : \"tweet was made by the bot's account, we can't retweet stuff made by us\",\n",
    "                        -6 : \"tweet is not in desired language\",\n",
    "                        -7 : \"tweet made by a forbidden-to-retweet user\"\n",
    "                    }\n",
    "                    \n",
    "                    logging(f'main(): {cases.get(valid_tweet,\"Invalid return\")}')\n",
    "                    write_json_and_updates_value(control_json,\n",
    "                                                 increment_success_amount = False)\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    logging('main(): Unexpected return for validate_and_retweet_tweet different than dict or int!! content: '+str(valid_tweet) +'type of return: '+str(type(valid_tweet)))\n",
    "                    write_json_and_updates_value(control_json,\n",
    "                                                 increment_success_amount = False)\n",
    "\n",
    "                logging(\"main(): Waiting 2 min to retrieve another tweet cuz we like safety\")\n",
    "                time.sleep(60*2) # sleep 2 min, so we dont reach the limit 100 tweets per hour\n",
    "         \n",
    "    except Exception as error:\n",
    "                # this is the only way i found to handle this weird exception\n",
    "        if 'status code = 401' in str(error) or 'status code = 400' in str(error):\n",
    "            logging('main(): INVALID CREDENTIALS, STOPPING BOT')\n",
    "            pymsgbox.alert('INVALID CREDENTIALS on JSON!!!', 'Stopping bot',timeout=15000)\n",
    "            want_to_insert_credentials = pymsgbox.confirm('Would you like to insert your credentials here? \\n or... update credentials on \\\\bot_files\\\\controls\\\\credentials.json', 'INSERT CREDENTIALS?', [\"Yes\", \"No, I'll update the json file\"])\n",
    "            if want_to_insert_credentials == 'Yes':\n",
    "                receive_information_overwrite_json(json=\"credentials\")\n",
    "                main()\n",
    "        else:\n",
    "            logging(f'main(): Unkown error: {error}')\n",
    "    \n",
    "    logging(render('end of lap', font=\"slick\", background='transparent'))\n",
    "    \n",
    "    pymsgbox.alert('$$$$$$$$$$$$$$ \\n END OF LAP\\n $$$$$$$$$$$$$', 'End of times',timeout=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticating(credential):\n",
    "    logging('\\n\\nfunction>>>>>authenticating')\n",
    "     \n",
    "    \"\"\"   \n",
    "    â–ˆâ€ƒâ–ˆâ–„â–‘â–ˆ\n",
    "    â–ˆâ€ƒâ–ˆâ–‘â–€â–ˆ    \n",
    "    \"\"\"\n",
    "        # credential         â€¢ <dictionary>                 â—‹ its keys will be used to authenticate\n",
    "        \n",
    "    \"\"\"\n",
    "    â–ˆâ–€â–ˆâ€ƒâ–ˆâ–‘â–ˆâ€ƒâ–€â–ˆâ–€\n",
    "    â–ˆâ–„â–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–‘â–ˆâ–‘\n",
    "    \"\"\"\n",
    "        # api                â€¢ <class 'tweepy.api.API'>     â—‹ authenticated api\n",
    "   \n",
    "    auth = tweepy.OAuthHandler(credential[\"api_key\"],\n",
    "                               credential[\"api_secret\"])\n",
    "    \n",
    "    auth.set_access_token(credential[\"access_token\"],\n",
    "                          credential[\"access_token_secret\"])\n",
    "\n",
    "    api = tweepy.API(auth,\n",
    "                     wait_on_rate_limit=True,\n",
    "                     wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    logging(render(f'welcome,', font=\"slick\", background='transparent'))\n",
    "    logging(render(f'{str(api.me().screen_name)}!', font=\"block\", background='transparent'))\n",
    "    \n",
    "    logging('\\nfunction<<<<<authenticating\\n\\n')\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_retweet_tweet(api, tweet, dict_tweets_info, dict_attributes_info, searched_word):\n",
    "    logging('\\n\\nfunction>>>>>validate_and_retweet_tweet')\n",
    "    \n",
    "    \"\"\"   \n",
    "    â–ˆâ€ƒâ–ˆâ–„â–‘â–ˆ\n",
    "    â–ˆâ€ƒâ–ˆâ–‘â–€â–ˆ    \n",
    "    \"\"\"\n",
    "        # api                   â€¢ <class 'tweepy.api.API'>    â—‹ authenticated api\n",
    "        # tweet                 â€¢ <tweet object>              â—‹ one single tweet object and its attributes \n",
    "        # dict_tweets_info      â€¢ <dictionary>                â—‹ empty, to be filled with informations from this tweet object\n",
    "        # dict_attributes_info  â€¢ <dictionary>                â—‹ attributes setted up on json to rule validations for this bot\n",
    "        # searched_word         â€¢ <string>                    â—‹ seeking term (will be used here to validate the inner content of the tweet) \n",
    "    \n",
    "    \"\"\"\n",
    "    â–ˆâ–€â–ˆâ€ƒâ–ˆâ–‘â–ˆâ€ƒâ–€â–ˆâ–€\n",
    "    â–ˆâ–„â–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–‘â–ˆâ–‘\n",
    "    \"\"\"\n",
    "        # -1           â—‹ didn't found the searched_word on tweet.text it self \n",
    "        # -2           â—‹ forbidden language (japanese, korean, arabic etc the ones we got problems to recognize the searched word)\n",
    "        # -3           â—‹ you have already retweeted this Tweet\n",
    "        # -4           â—‹ RateLimitError\n",
    "        # -5           â—‹ tweet was made by the bot's account, we can't retweet stuff made by us \n",
    "        # -6           â—‹ tweet is not in desired language\n",
    "        # -7           â—‹ tweet made by a forbidden-to-retweet user\n",
    "        # dict         â—‹ in a valid situation, returns a populated dictionary containing this tweet's data after retweeting it\n",
    "\n",
    "    try: \n",
    "\n",
    "        logging('appending infos retrieved to dictionary')\n",
    "        dict_tweets_info['created_at'].append(str(tweet.created_at))\n",
    "        dict_tweets_info['tweet_ID'].append(str(tweet.id))\n",
    "        dict_tweets_info['user'].append(str(tweet.user.screen_name))\n",
    "        dict_tweets_info['tweet_content'].append((tweet.full_text))\n",
    "        dict_tweets_info['place'].append(str(tweet.place))\n",
    "        dict_tweets_info['language'].append(str(tweet.lang))\n",
    "        dict_tweets_info['source'].append(str(tweet.source_url).replace(\"http://twitter.com/download/\",\"\"))\n",
    "    \n",
    "        logging('----------------------------------------')\n",
    "        logging(f'raw dict_tweets_info after appending: \\n {dict_tweets_info}')\n",
    "        logging('----------------------------------------')\n",
    "        \n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    # --------------------------------- FILTERING BEFORE RETWEET ----------------------------------------------\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        logging('validate_and_retweet_tweet(): filtering BEFORE retweet')\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        string_lang_content = \"\".join(dict_tweets_info['language'] )  # ğ­ğ®ğ«ğ§ğ¬ ğ¥ğ¢ğ¬ğ­ ğ¢ğ§ğ­ğ¨ ğ¬ğ­ğ«ğ¢ğ§ğ  ğ­ğ¨ ğœğ¨ğ¦ğ©ğšğ«ğ\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------- checking if it's in one of the ENFORCED languages ----------------------\n",
    "        # -----------------------------------------------------------------------------------------------------        \n",
    "        logging(':::: filtering :::: enforced languages')\n",
    "        if dict_attributes_info[\"restrict_tweets_to_these_languages\"]:\n",
    "            # only comes here if list is not empty! we have to enforce the languages on the list\n",
    "            logging(f'these are the current enforced languages: {dict_attributes_info[\"restrict_tweets_to_these_languages\"]}')\n",
    "            if not string_lang_content in dict_attributes_info[\"restrict_tweets_to_these_languages\"]:\n",
    "                logging('ENFORCED LANG not OK: this tweet is not in enforced languages list, we wont retweet any other language!')\n",
    "                returning = -6\n",
    "            else: \n",
    "                logging('ENFORCED LANG OK: this tweet is allowed by the enforced languages list: '+string_lang_content)        \n",
    "        else:\n",
    "            logging('ENFORCED LANG OK: RESTRICTION LIST IS EMPTY, WE DONT NEED TO ENFORCE ANY LANGUAGE')\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------- checking if it's in one of the FORBIDDEN languages ---------------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        logging(':::: filtering :::: forbidden languages')\n",
    "        if string_lang_content in dict_attributes_info[\"forbidden_languages_to_retweet\"]:\n",
    "            logging('FORBIDDEN LANG not OK: dumb robot, tweet is not in an understandable language so its content will be wrongly evaluated, we stop here')\n",
    "            returning = -2\n",
    "        else: \n",
    "            logging('FORBIDDEN LANG OK: tweet is not in any forbidden language! language is actually: '+string_lang_content)\n",
    "            \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------- checking if the searched word really is on tweet content ---------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        logging(':::: filtering :::: searched word on tweet text')\n",
    "        string_tweet_content = \"\".join(dict_tweets_info['tweet_content'] ) # turns list into string to compare\n",
    "        if not searched_word in string_tweet_content.lower():\n",
    "            logging('SEARCHED WORD not OK: we havent found '+ searched_word + ' on tweet content')\n",
    "            # NO WAY it's gonna retweet something that has NOT the word on the text\n",
    "            returning = -1\n",
    "        else:\n",
    "            logging('SEARCHED WORD OK: we found the searched word on tweet content!')\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        user_of_this_tweet = str(tweet.user.screen_name)   # ğ­ğ®ğ«ğ§ğ¬ ğ¬ğœğ«ğğğ§_ğ§ğšğ¦ğ ğšğ­ğ­ğ«ğ¢ğ›ğ®ğ­ğ ğ¢ğ§ğ­ğ¨ ğ¬ğ­ğ«ğ¢ğ§ğ  ğ­ğ¨ ğœğ¨ğ¦ğ©ğšğ«ğ\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ------------------------- checking if THIS tweet's user is among the forbidden users ---------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        logging(':::: filtering :::: forbidden users')\n",
    "        if dict_attributes_info[\"users_to_not_retweet\"]:\n",
    "            # only comes here if list is not empty! we have to block retweets from these users on list\n",
    "            logging('these are the current forbidden users to retweet: '+ str(dict_attributes_info[\"users_to_not_retweet\"]))\n",
    "            if str(tweet.user.screen_name) in dict_attributes_info[\"users_to_not_retweet\"]:\n",
    "                logging('FORBIDDEN USERS not OK: this tweet was made by a forbidden-to-retweet user')\n",
    "                returning = -7\n",
    "            else: \n",
    "                logging('FORBIDDEN USERS OK: we are allowed to retweet tweets from @'+ user_of_this_tweet)        \n",
    "        else:\n",
    "            logging('FORBIDDEN USERS OK: LIST IS EMPTY, WE DONT NEED TO IGNORE ANY USER')\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ------------------------- checking if THIS tweet's user is also the authenticated user --------------\n",
    "        # -------------------------------- (so we dont retweet our ğ¨ğ°ğ§ tweets) -------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        logging(\":::: filtering :::: tweet's user vs authenticated one\")\n",
    "        my_user_object = api.me()\n",
    "        if str(my_user_object.screen_name) == user_of_this_tweet:\n",
    "            logging('you are @'+ str(my_user_object.screen_name))\n",
    "            logging('OWN AUTHORSHIP not OK: this tweet was made by yourself using your bot profile or is an old RETWEET!! both cases we wont retweet it again')\n",
    "            returning = -5\n",
    "        else:\n",
    "            logging('OWN AUTHORSHIP OK: this user is not you! you: '+ str(my_user_object.screen_name) + ' VS this user: '+ user_of_this_tweet +', that s great')\n",
    "        \n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    # ---------------------------------- OK, RETWEET ACTION ! -------------------------------------------------\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "        logging('retweeting â†â†â†â†â†â†â†â†â†â†â†â†â†')\n",
    "        api.retweet(tweet.id)\n",
    "        logging('â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’ retweeted') # if an exception is raised during retweet method, we wont arrive here\n",
    "        return dict_tweets_info\n",
    "    \n",
    "    except tweepy.TweepError as e: \n",
    "        if e.api_code == 327:\n",
    "            logging('Exception Code 327: You have already retweeted this Tweet')\n",
    "            returning = -3\n",
    "        \n",
    "    except tweepy.RateLimitError as e:\n",
    "        logging('RateLimitError')\n",
    "        logging('Unknown error: '+str(e))\n",
    "        logging('according to internet, sleeping for 15 min should solve...')\n",
    "        time.sleep(60 * 15)  # we saw rate limit is ignored after 15 min ??? ///not confirmed hypothesis///\n",
    "        returning = -4\n",
    "        \n",
    "    logging('\\nfunction<<<<<validate_and_retweet_tweet\\n\\n')    \n",
    "    return returning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_and_updates_value(path, increment_success_amount = False, initialize = False):\n",
    "    logging('\\n\\nfunction>>>>>write_json_and_updates_value')\n",
    "    \n",
    "    \"\"\"   \n",
    "    â–ˆâ€ƒâ–ˆâ–„â–‘â–ˆ\n",
    "    â–ˆâ€ƒâ–ˆâ–‘â–€â–ˆ    \n",
    "    \"\"\"\n",
    "        # path                           â€¢ <string>          â—‹ control json path\n",
    "        # increment_success_amount       â€¢ <bool>            â—‹ boolean flag to update or not a specific key\n",
    "        # inicializar                    â€¢ <bool>            â—‹ boolean flag to reset (set to 0) or not all the keys\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_date = now.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    # -------------------------------- trying to read from file -----------------------------------------------\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    logging(f'write_json_and_updates_value(): loading json file into dictionary, so we can manipulate values')\n",
    "    \n",
    "    try:\n",
    "        with open(path) as json_file:\n",
    "            tweets_status = json.load(json_file)\n",
    "            \n",
    "    except IOError as io_e:\n",
    "        if initialize:\n",
    "            logging(f'write_json_and_updates_value(): file does not exist yet but we will create because we got the initialize parameter as true')\n",
    "        else:\n",
    "            logging(f'write_json_and_updates_value(): IO ERROR BUT WE WERE NOT SUPPOSED TO INITIALIZE THE FILE NOW: {io_e}')\n",
    "                \n",
    "    except Exception as e:\n",
    "        logging(f'write_json_and_updates_value(): UNKOWN PROBLEMS WHEN TRYING TO READ JSON FILE: {e}')\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    # ---------------------------------- writing on file ------------------------------------------------------\n",
    "    # ------- if our current date is the same of the file, we increase amount of tweets -----------------------\n",
    "    # ----- if different, amount of everything is ZERO because it's the first time running of today !!!! ------\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    if initialize or tweets_status['current_date'] != current_date: \n",
    "        logging('write_json_and_updates_value(): different dates, OR initializing parameter says true, so we need to update the current_date and also reset all the values to 0 ')\n",
    "        with open(path, 'w') as f:\n",
    "            try:\n",
    "                content = {\"current_date\": current_date,\n",
    "                           \"amount_of_tweets\": 0,\n",
    "                           \"total_amount_including_failure\":0}\n",
    "                json.dump(content, f)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging('write_json_and_updates_value(): decode error but will try raw writing')\n",
    "                f.write(contenting)\n",
    "    else: \n",
    "        logging('write_json_and_updates_value(): same date of file, bot was online today!! so, just update the value of tweets')\n",
    "        if increment_success_amount:\n",
    "                logging('write_json_and_updates_value(): increases both keys - failure and success counter')\n",
    "                # vai incrementtar o total com falhas tb + o total dos sucessos\n",
    "                tweets_status[\"amount_of_tweets\"] = tweets_status[\"amount_of_tweets\"]+1 \n",
    "                tweets_status['total_amount_including_failure'] = tweets_status['total_amount_including_failure']+1\n",
    "                with open(path, 'w') as f:\n",
    "                    try:\n",
    "                        json.dump(tweets_status, f)\n",
    "                    except json.JSONDecodeError:\n",
    "                        logging('decode error but will try raw writing')\n",
    "                        f.write(contenting)\n",
    "                    \n",
    "        elif not increment_success_amount: \n",
    "                logging('increasing amount of the ones who failure')\n",
    "                     # increasing amount of the ones who failure \n",
    "                tweets_status['total_amount_including_failure'] = tweets_status['total_amount_including_failure']+1\n",
    "\n",
    "                with open(path, 'w') as f:\n",
    "                    try:\n",
    "                        json.dump(tweets_status, f)\n",
    "\n",
    "                    except json.JSONDecodeError:\n",
    "                        logging('decode error but will try raw writing')\n",
    "                        f.write(contenting)\n",
    "                        \n",
    "    logging('\\nfunction<<<<<write_json_and_updates_value\\n\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_infos_to_csv(valid_tweet):\n",
    "    logging('\\n\\nfunction>>>>>exporting_infos_to_csv')\n",
    "        \n",
    "    \"\"\"   \n",
    "    â–ˆâ€ƒâ–ˆâ–„â–‘â–ˆ\n",
    "    â–ˆâ€ƒâ–ˆâ–‘â–€â–ˆ    \n",
    "    \"\"\"\n",
    "        # valid tweet        â€¢ <dictionary>          â—‹ dictionary holding all informations we retrieved from one specific tweet\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # ------------------------- fetch today's DATE in DD/MM/YYY format and turns into DD-MM-YYYY ------------------\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%d/%m/%Y\").replace(\"/\",\"-\").replace(':',\"-\").replace(',','--').replace(\" \",\"\")\n",
    "\n",
    "    CSV_path = useful_variables.exported_data_folder+'\\\\dados_'+timestamp+'.csv'\n",
    "    logging(f\"today's CSV path: {CSV_path}\")\n",
    "\n",
    "    logging(f'valid_tweet : {valid_tweet}')\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # -------- to exclusively append tweet's informations, we CANT append dict directly, otherwise the function ---\n",
    "    # ------------- will append header (dict keys) row + informations (dict values) row for EVERY tweet -----------\n",
    "    # --------- so we turn the dict values into a list and we only append header if it's a new CSV (new day) ------\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------------- turning dict values into a list ----------------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    dict_values_in_list_version = []\n",
    "    for key, value in valid_tweet.items():\n",
    "        dict_values_in_list_version.append(\"\".join(value))\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        # -------- forcing Tweet ID to be written as string on sheet, so it doesnt truncate as scientific notation --\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    dict_values_in_list_version[1] = '\\''+dict_values_in_list_version[1]\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        # ---- for some reason, a lot of tweets come with a \\n character, which unduly makes CSV skip lines --------\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "     \n",
    "    for index, field in enumerate(dict_values_in_list_version):\n",
    "        dict_values_in_list_version[index] = field.replace('\\n',\"\")\n",
    "            \n",
    "    logging(f'dict_values_in_list_version: {dict_values_in_list_version}')\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        # --------- if today's CSV already exists, we will append only this specific tweet's DETAILS to file --------\n",
    "        # ----------------- elseways we append the header (creating a new file) -------------------------------------\n",
    "        # ------------------- and THEN append current tweet's details normally --------------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    if not os.path.exists(CSV_path):\n",
    "        logging('today s csv does not exist yet, creating it and appending header')\n",
    "        header_csv = ['created_at','tweet_ID','user','tweet_content','place','language','source'] \n",
    "        with open(CSV_path, \"a\", encoding=\"utf-8\", newline='') as file:\n",
    "            wr = csv.writer(file)\n",
    "            wr.writerow(header_csv)\n",
    "            \n",
    "    with open(CSV_path, \"a\", encoding=\"utf-8\", newline='') as file:\n",
    "        logging('writing tweet details on CSV file')\n",
    "        wr = csv.writer(file)\n",
    "        wr.writerow(dict_values_in_list_version)\n",
    "        \n",
    "    logging('\\nfunction>>>>>exporting_infos_to_csv\\n\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(text_to_log=\"\"):\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "    # ------------------- converts into string the parameter we want to write on log file -----------------------\n",
    "    # ------------------------- just in case we received another variable type ----------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    text_to_log = str(text_to_log)\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "    # --------------------------- fetchs timestamp to append within received text -------------------------------\n",
    "    # ---------- fetchs current date to create new log file or append to the current one ------------------------\n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%d/%m/%Y\").replace(\"/\",\"-\")\n",
    "    timestamp = now.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---- retrieves directory where our robot is running and concatenate the path to the current day's ---\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    log_path = useful_variables.logs_folder+'\\\\log_'+date+'.txt'\n",
    "    \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ----- appending to file of the day: timestamp + parameter's content ---------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    with open(log_path, 'a+',encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(timestamp+ ' - ' + text_to_log+'\\n')\n",
    "    \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ------ printing on console ----------------------------------------------------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "    print(timestamp+ ' - ' + text_to_log)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_information_overwrite_json(json):      \n",
    "    logging('\\n\\nfunction>>>>>receive_information_overwrite_json')\n",
    "    \n",
    "    if json == \"credentials\":\n",
    "        new_api_key = pymsgbox.prompt('Insert your API KEY', default='3x4mPL3-j13j2o38s09dsaf')\n",
    "        new_api_secret = pymsgbox.prompt('Insert your API SECRET', default='3x4mPL3-j13j2o38s09dsaf')\n",
    "        new_bearer_token = pymsgbox.prompt('Insert your BEARER TOKEN', default='3x4mPL3-j13j2o38s09dsaf')\n",
    "        new_access_token = pymsgbox.prompt('Insert your ACCESS TOKEN', default='3x4mPL3-j13j2o38s09dsaf')\n",
    "        new_access_token_secret = pymsgbox.prompt('Insert your ACCESS TOKEN SECRET', default='3x4mPL3-j13j2o38s09dsaf')\n",
    "\n",
    "        with open(useful_variables.credentials_json, 'w') as f:\n",
    "            try:\n",
    "                content = {\"api_key\" : new_api_key,\n",
    "                           \"api_secret\" : new_api_secret,\n",
    "                           \"bearer_token\" : new_bearer_token,\n",
    "                           \"access_token\" : new_access_token,\n",
    "                           \"access_token_secret\" : new_access_token_secret}\n",
    "                json.dump(content, f)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging('decode error but will try raw writing')\n",
    "                f.write(contenting)\n",
    "            \n",
    "            \n",
    "    elif json == \"attributes\":       \n",
    "            new_words_to_search = pymsgbox.prompt('Insert the words you want to retweet (separeted by COMMA only) \\nExample: bla, blabla, blablabla', default='word1,word2,word3')\n",
    "            logging('inputted new_words_to_search: '+ new_words_to_search)\n",
    "            new_users_to_not_retweet = pymsgbox.prompt('Insert users you want to ban retweets from (separeted by COMMA only)\\nExample: bla, blabla, blablabla', default='user1,user2,user3')\n",
    "            logging('inputted new_users_to_not_retweet: '+ new_users_to_not_retweet)\n",
    "            new_forbidden_languages_to_retweet = pymsgbox.prompt('Do you want to forbid some specific language ? Insert them by using its standard abbreviation\\nExample: pt, en  in case you dont want to see tweets in portuguese and english\\n\\nIf you want to retweet all languages, please dont write anything', default = 'en,pt')\n",
    "            logging('inputted new_forbidden_languages_to_retweet: '+ new_forbidden_languages_to_retweet)\n",
    "            new_restrict_tweets_to_these_languages = pymsgbox.prompt('Do you want to restrict ALL tweets to one single language? (Or some specific ones) Insert them by using its standard abbreviation\\nExample: ja,ko  in case you ONLY want to see japanese and korean tweets!\\n\\nIf you dont wanna restrict tweets to some specific language, please dont write anything', default = \"ja\")\n",
    "            logging('inputted new_restrict_tweets_to_these_languages: '+ new_restrict_tweets_to_these_languages)\n",
    "            \n",
    "              \n",
    "            content = {\"words_to_search\" : [],\n",
    "                           \"users_to_not_retweet\" : [],\n",
    "                           \"forbidden_languages_to_retweet\" : [],\n",
    "                           \"restrict_tweets_to_these_languages\" : [] }\n",
    "            \n",
    "            if new_words_to_search in [\"\",\" \"]:\n",
    "                pass\n",
    "            else:\n",
    "                new_words_to_search = new_words_to_search.split(\",\")\n",
    "                list_new_words_to_search = []\n",
    "                for word in new_words_to_search:\n",
    "                    word = word.strip()  # cut out spaces at the beginning and at the end of the word\n",
    "                    list_new_words_to_search.append(word)\n",
    "                logging('new_words_to_search to be written on json: '+str(list_new_words_to_search))\n",
    "                content[\"words_to_search\"] = list_new_words_to_search\n",
    "\n",
    "            if new_users_to_not_retweet in [\"\",\" \"]:\n",
    "                pass\n",
    "            else:\n",
    "                new_users_to_not_retweet = new_users_to_not_retweet.split(\",\")\n",
    "                list_users_to_not_retweet = []\n",
    "                for word in new_users_to_not_retweet:\n",
    "                    word = word.strip()  # cut out spaces at the beginning and at the end of the word\n",
    "                    list_users_to_not_retweet.append(word)\n",
    "                logging('new_users_to_not_retweet to be written on json: '+str(list_users_to_not_retweet))\n",
    "                content[\"users_to_not_retweet\"] = list_users_to_not_retweet\n",
    "                \n",
    "    \n",
    "            if new_forbidden_languages_to_retweet in [\"\",\" \"]:\n",
    "                pass\n",
    "            else: \n",
    "                new_forbidden_languages_to_retweet = new_forbidden_languages_to_retweet.split(',')\n",
    "                list_new_forbidden_languages_to_retweet = []\n",
    "                for word in new_forbidden_languages_to_retweet:\n",
    "                    word = word.strip()  # cut out spaces at the beginning and at the end of the word\n",
    "                    list_new_forbidden_languages_to_retweet.append(word)\n",
    "                logging('new_forbidden_languages_to_retweet to be written on json: '+str(list_new_forbidden_languages_to_retweet))\n",
    "                content[\"forbidden_languages_to_retweet\"] = list_new_forbidden_languages_to_retweet\n",
    "            \n",
    "            if new_restrict_tweets_to_these_languages in [\"\",\" \"]:\n",
    "                pass\n",
    "            else:\n",
    "                new_restrict_tweets_to_these_languages = new_restrict_tweets_to_these_languages.split(',')\n",
    "                list_new_restrict_tweets_to_these_languages = []\n",
    "                for word in new_restrict_tweets_to_these_languages:\n",
    "                    word = word.strip()  # cut out spaces at the beginning and at the end of the word\n",
    "                    list_new_restrict_tweets_to_these_languages.append(word)\n",
    "                logging('new_restrict_tweets_to_these_languages to be written on json: '+str(list_new_restrict_tweets_to_these_languages))\n",
    "                content[\"restrict_tweets_to_these_languages\"] = list_new_restrict_tweets_to_these_languages\n",
    "                \n",
    "            with open(useful_variables.attributes_json, 'w') as f:\n",
    "                try:\n",
    "                    for key, value in content.items():\n",
    "                        json.dumps(content, f)\n",
    "\n",
    "                except AttributeError:\n",
    "                    logging('decode error but will try raw writing')\n",
    "                    f.write(str(content).replace(\"'\",'\"'))\n",
    "                    \n",
    "    logging('\\nfunction<<<<<receive_information_overwrite_json\\n\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liveshow(text=\"\",title=\"Are we on air?\",timeout=5000):\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # live show Definition (n.): \n",
    "    #        \"ğ“ğ’¾ğ“‹ğ‘’ ğ’·ğ“‡ğ‘œğ’¶ğ’¹ğ’¸ğ’¶ğ“ˆğ“‰, ğ’·ğ“‡ğ‘œğ’¶ğ’¹ğ’¸ğ’¶ğ“ˆğ“‰ ğ“‰ğ’½ğ’¶ğ“‰ ğ’¾ğ“ˆ ğ’¶ğ’¾ğ“‡ğ‘’ğ’¹ ğ’¾ğ“ƒ ğ“‡ğ‘’ğ’¶ğ“-ğ“‰ğ’¾ğ“‚ğ‘’ \" \n",
    "    #                          https://www.dictionarist.com/live+show\n",
    "    # ----------------------------------------------------------------\n",
    "\n",
    "    logging(text)\n",
    "    pymsgbox.alert(text = text,\n",
    "                  title = title,\n",
    "                  timeout = timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checks_if_necessary_folders_exist_otherwise_create_them():\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # ---------------------  CREATES INTO SCRIPT DIRECTORY ALL NECESSARY FOLDERS  ------------------\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    returning = 1 \n",
    "    try:\n",
    "        if not os.path.exists(useful_variables.logs_folder):\n",
    "            pymsgbox.alert(text=\"Creating logs' folder\", title='Setting bot up', button='OK',timeout=4500)\n",
    "            os.makedirs(useful_variables.logs_folder)\n",
    "            logging(\"Creating logs' folder\")\n",
    "            returning = [\"probably first time\"]\n",
    "        else:\n",
    "            liveshow(f'{useful_variables.logs_folder} already exists')\n",
    "\n",
    "        if not os.path.exists(useful_variables.controls_folder):\n",
    "            pymsgbox.alert(text='Creating controls folder', title='Setting bot up', button='OK',timeout=4500)\n",
    "            os.makedirs(useful_variables.controls_folder)\n",
    "            logging(\"Creating controls folder\")\n",
    "            returning = [\"probably first time\"]\n",
    "        else:\n",
    "            liveshow(f'{useful_variables.controls_folder} already exists')\n",
    "\n",
    "        if not os.path.exists(useful_variables.exported_data_folder):\n",
    "            pymsgbox.alert(text='Creating exported_data folder', title='Setting bot up', button='OK',timeout=4500)\n",
    "            os.makedirs(useful_variables.exported_data_folder)\n",
    "            logging(\"Creating exported_data folder\")\n",
    "            returning = [\"probably first time\"]\n",
    "        else:\n",
    "            liveshow(f'{useful_variables.exported_data_folder} already exists')\n",
    "\n",
    "    except Exception as error:\n",
    "        logging(f'Unknown error: {error}')\n",
    "        returning = str(error)\n",
    "    \n",
    "    return returning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checks_if_necessary_files_exist_otherwise_create_them():\n",
    "    logging('\\n\\nfunction>>>>>checks_if_necessary_files_exist_otherwise_create_them')\n",
    "   \n",
    "    \"\"\"\n",
    "    â–ˆâ–€â–ˆâ€ƒâ–ˆâ–‘â–ˆâ€ƒâ–€â–ˆâ–€\n",
    "    â–ˆâ–„â–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–‘â–ˆâ–‘\n",
    "    \"\"\" \n",
    "    # -1     â—‹ invalid attributes: FOUND ATTRIBUTES FILE BUT some value on attributes dict is not list type ('a' : ['LIST','LIST'])\n",
    "    # -2     â—‹ invalid attributes: FOUND ATTRIBUTES FILE BUT to exclude a language from retweeting and ask to retweet the same language is contraditory\n",
    "    # string â—‹ json files DIDN'T exist, but we created the templates\n",
    "    # dict   â—‹ json files exist and the validation for all json files successed\n",
    "    \n",
    "    returning = \"we assume this is the first time running the bot \"\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # ---------- checking if control json exists, otherwise we create it -------------------\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    control_json = useful_variables.control_json\n",
    "    if not os.path.exists(control_json):\n",
    "        logging(\"control json not found, gotta create it\")\n",
    "        write_json_and_updates_value(control_json,\n",
    "                                     increment_success_amount = False,\n",
    "                                     initialize = True)\n",
    "    else:\n",
    "        logging(f'{control_json} already exists')\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------    \n",
    "    # ---------- checking if credentials json exists, otherwise we create it -------------------\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    \n",
    "    credentials_json = useful_variables.credentials_json\n",
    "    if not os.path.exists(credentials_json):\n",
    "        logging(\"credentials json not found, gotta create it using a template\")\n",
    "        \n",
    "        with open(credentials_json, 'w') as f:\n",
    "            try:\n",
    "                content_template = {\"api_key\" : \"examplen9masss23423553252ffffffe\",\n",
    "                           \"api_secret\" : \"examplefa1asfsafsafsa32434fdfsfsdfddsfsfddfdfsfd\",\n",
    "                           \"bearer_token\" : \"exampleAAAAAAAAAADFDSFGDDGGDAGDFHDFHBV424G4023fe032402320F242WER355W31tg21e454F4E4ER4Esfdsdfdfs\",\n",
    "                           \"access_token\" : \"example13371788gfdfgdfgdfgd344544gdfgfdsj5jytjjy\",\n",
    "                           \"access_token_secret\" : \"examplect42gdfhf5y66hsvbbgfhC91Rhfghgf45t4555552432324235\"}\n",
    "                json.dump(content_template, f)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging('decode error but will try raw writing')\n",
    "                f.write(content_template)\n",
    "                \n",
    "    else:\n",
    "        logging(f'{credentials_json} already exists')\n",
    "        \n",
    "    # ------------------------------------------------------------------------------------------    \n",
    "    # ---------- checking if attributes json exists, otherwise we create it --------------------\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    \n",
    "    attributes_json = useful_variables.attributes_json\n",
    "    \n",
    "    content_template = {\"words_to_search\" : ['zolpidem','ambien'],\n",
    "                        \"users_to_not_retweet\" : ['user1','user2'],\n",
    "                        \"forbidden_languages_to_retweet\" : ['ja','ko','und','fa','ar'],\n",
    "                        \"restrict_tweets_to_these_languages\" : [],\n",
    "                        \"amount_of_tweets_to_retrieve_for_every_word\": 1800 }\n",
    "    \n",
    "    if not os.path.exists(attributes_json):\n",
    "        logging(\"attributes json not found, gotta create it using a valid template\")\n",
    "        \n",
    "        with open(attributes_json, 'w') as f:\n",
    "            try:\n",
    "                \n",
    "                json.dump(content_template, f)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging('decode error but will try raw writing')\n",
    "                f.write(content_template)\n",
    "                \n",
    "            finally:\n",
    "                returning = \"attributes json had to be created, probably this is the first time of this user\"\n",
    "                \n",
    "    else:\n",
    "        # -------------------------------------------------------------------------------------\n",
    "        # ---------------- if file exists already, we will validate any inconsistency ---------\n",
    "        # -------------------------------------------------------------------------------------\n",
    "        \n",
    "        logging(f'{attributes_json} already exists')\n",
    "        logging('let s validate its content')\n",
    "        with open(attributes_json) as json_file:\n",
    "            returning = content_template\n",
    "            dict_attributes_info = json.load(json_file)\n",
    "            \n",
    "            # ----------- all values have to be LIST type -----------------------\n",
    "            \n",
    "            for key, value in dict_attributes_info.items():\n",
    "                if key == \"amount_of_tweets_to_retrieve_for_every_word\":\n",
    "                    continue # this is the only key that has not to be list type \n",
    "                \n",
    "                if not type(value) is list:\n",
    "                    liveshow(f'YOU VE CHANGED THE TYPE OF SOME VALUE ON JSON! the value of {key} is not a list and it has to be!\\nPLEASE, DELETE THE ATTRIBUTES.JSON FILE, restart the bot AND FOLLOW THE INITIAL TEMPLATE we will create! \\n\\n\\nfile location: \\\\bot_files\\\\controls\\\\attributes.json\\n\\n', 'BOT CANNOT START WITH INVALID ATTRIBUTES')\n",
    "                    logging(f'the invalid key is {key}, because {value} is not list type')\n",
    "                    returning = -1\n",
    "            \n",
    "            # ----------- cant have same value on _restrict and _forbiden -------\n",
    "            \n",
    "            for language in dict_attributes_info['restrict_tweets_to_these_languages']:\n",
    "                if language in dict_attributes_info['forbidden_languages_to_retweet']:\n",
    "                    liveshow(f'you cant ask us to only retweet things in the same language you WANT TO PROHIBIT retweeting! you inserted {language} in both keys: restricting and forbidding!\\nPLEASE UPDATE JSON FILE ON \\\\bot_files\\\\controls\\\\attributes.json and try again','what?')\n",
    "                    returning = -2\n",
    "                \n",
    "            # ----------- cant have empty value on words_to_search -------------\n",
    "            \n",
    "            if not dict_attributes_info[\"words_to_search\"]:\n",
    "                liveshow(\"THIS IS A RETWEET BOT, if we have no words to look for, what do you want us to do? \\nPlease update attributes.json inside of CONTROLS folder and set a list of words\",\"Oh no\",8000)\n",
    "                returning = -3\n",
    "                \n",
    "    logging('\\nfunction<<<<<checks_if_necessary_files_exist_otherwise_create_them\\n\\n')            \n",
    "    return returning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from useful_variables.ipynb\n",
      "24/02/2021, 18:22:40 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\logs already exists\n",
      "24/02/2021, 18:22:42 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\controls already exists\n",
      "24/02/2021, 18:22:43 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\exported_data already exists\n",
      "24/02/2021, 18:22:43 - \n",
      "\n",
      "function>>>>>checks_if_necessary_files_exist_otherwise_create_them\n",
      "24/02/2021, 18:22:43 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\controls\\amount_of_tweets_from_today.json already exists\n",
      "24/02/2021, 18:22:43 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\controls\\credentials.json already exists\n",
      "24/02/2021, 18:22:43 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\controls\\attributes.json already exists\n",
      "24/02/2021, 18:22:43 - let s validate its content\n",
      "24/02/2021, 18:22:43 - \n",
      "function<<<<<checks_if_necessary_files_exist_otherwise_create_them\n",
      "\n",
      "\n",
      "24/02/2021, 18:22:43 - main(): ok, all files were validated, we may start the bot!!!!\n",
      "24/02/2021, 18:22:43 - \n",
      "\n",
      "â•±â•­â”â”â•®â•±â•±â•­â”â”â”â•®â•±â•­â”â”â”â•®â•±â•­â”â”â•®â•±â•­â”â•®â•±â•­â•®â•±â•±â•±â•±â•±â•­â”â”â”â•®â•±â•­â”â”â”â•®â•±â•±â•±â•±â•±â•­â•®â•±â•±â•±â•±â•­â”â”â”â•®â•±â•­â”â”â”â•®â•±\n",
      "â•±â”ƒâ•­â•®â”ƒâ•±â•±â”ƒâ•­â”â”â•¯â•±â”ƒâ•­â”â•®â”ƒâ•±â•°â”«â”£â•¯â•±â”ƒâ”ƒâ•°â•®â”ƒâ”ƒâ•±â•±â•±â•±â•±â”ƒâ•­â”â•®â”ƒâ•±â”ƒâ•­â”â”â•¯â•±â•±â•±â•±â•±â”ƒâ”ƒâ•±â•±â•±â•±â”ƒâ•­â”â•®â”ƒâ•±â”ƒâ•­â”â•®â”ƒâ•±\n",
      "â•±â”ƒâ•°â•¯â•°â•®â•±â”ƒâ•°â”â”â•®â•±â”ƒâ”ƒâ•±â•°â•¯â•±â•±â”ƒâ”ƒâ•±â•±â”ƒâ•­â•®â•°â•¯â”ƒâ•±â•±â•±â•±â•±â”ƒâ”ƒâ•±â”ƒâ”ƒâ•±â”ƒâ•°â”â”â•®â•±â•±â•±â•±â•±â”ƒâ”ƒâ•±â•±â•±â•±â”ƒâ”ƒâ•±â”ƒâ”ƒâ•±â”ƒâ•°â”â•¯â”ƒâ•±\n",
      "â•±â”ƒâ•­â”â•®â”ƒâ•±â”ƒâ•­â”â”â•¯â•±â”ƒâ”ƒâ•­â”â•®â•±â•±â”ƒâ”ƒâ•±â•±â”ƒâ”ƒâ•°â•®â”ƒâ”ƒâ•±â•±â•±â•±â•±â”ƒâ”ƒâ•±â”ƒâ”ƒâ•±â”ƒâ•­â”â”â•¯â•±â•±â•±â•±â•±â”ƒâ”ƒâ•±â•­â•®â•±â”ƒâ•°â”â•¯â”ƒâ•±â”ƒâ•­â”â”â•¯â•±\n",
      "â•±â”ƒâ•°â”â•¯â”ƒâ•±â”ƒâ•°â”â”â•®â•±â”ƒâ•°â”»â”â”ƒâ•±â•­â”«â”£â•®â•±â”ƒâ”ƒâ•±â”ƒâ”ƒâ”ƒâ•±â•±â•±â•±â•±â”ƒâ•°â”â•¯â”ƒâ•±â”ƒâ”ƒâ•±â•±â•±â•±â•±â•±â•±â•±â”ƒâ•°â”â•¯â”ƒâ•±â”ƒâ•­â”â•®â”ƒâ•±â”ƒâ”ƒâ•±â•±â•±â•±\n",
      "â•±â•°â”â”â”â•¯â•±â•°â”â”â”â•¯â•±â•°â”â”â”â•¯â•±â•°â”â”â•¯â•±â•°â•¯â•±â•°â”â•¯â•±â•±â•±â•±â•±â•°â”â”â”â•¯â•±â•°â•¯â•±â•±â•±â•±â•±â•±â•±â•±â•°â”â”â”â•¯â•±â•°â•¯â•±â•°â•¯â•±â•°â•¯â•±â•±â•±â•±\n",
      "\n",
      "\n",
      "24/02/2021, 18:22:46 - \n",
      "\n",
      "function>>>>>authenticating\n",
      "24/02/2021, 18:22:46 - \n",
      "\n",
      "â•±â•­â•®â•­â•®â•­â•®â•±â•­â”â”â”â•®â•±â•­â•®â•±â•±â•±â•±â•­â”â”â”â•®â•±â•­â”â”â”â•®â•±â•­â”â•®â•­â”â•®â•±â•­â”â”â”â•®â•±â•±â•±â•±\n",
      "â•±â”ƒâ”ƒâ”ƒâ”ƒâ”ƒâ”ƒâ•±â”ƒâ•­â”â”â•¯â•±â”ƒâ”ƒâ•±â•±â•±â•±â”ƒâ•­â”â•®â”ƒâ•±â”ƒâ•­â”â•®â”ƒâ•±â”ƒâ”ƒâ•°â•¯â”ƒâ”ƒâ•±â”ƒâ•­â”â”â•¯â•±â•±â•±â•±\n",
      "â•±â”ƒâ”ƒâ”ƒâ”ƒâ”ƒâ”ƒâ•±â”ƒâ•°â”â”â•®â•±â”ƒâ”ƒâ•±â•±â•±â•±â”ƒâ”ƒâ•±â•°â•¯â•±â”ƒâ”ƒâ•±â”ƒâ”ƒâ•±â”ƒâ•­â•®â•­â•®â”ƒâ•±â”ƒâ•°â”â”â•®â•±â•±â•±â•±\n",
      "â•±â”ƒâ•°â•¯â•°â•¯â”ƒâ•±â”ƒâ•­â”â”â•¯â•±â”ƒâ”ƒâ•±â•­â•®â•±â”ƒâ”ƒâ•±â•­â•®â•±â”ƒâ”ƒâ•±â”ƒâ”ƒâ•±â”ƒâ”ƒâ”ƒâ”ƒâ”ƒâ”ƒâ•±â”ƒâ•­â”â”â•¯â•±â•­â•®â•±\n",
      "â•±â•°â•®â•­â•®â•­â•¯â•±â”ƒâ•°â”â”â•®â•±â”ƒâ•°â”â•¯â”ƒâ•±â”ƒâ•°â”â•¯â”ƒâ•±â”ƒâ•°â”â•¯â”ƒâ•±â”ƒâ”ƒâ”ƒâ”ƒâ”ƒâ”ƒâ•±â”ƒâ•°â”â”â•®â•±â•°â”«â•±\n",
      "â•±â•±â•°â•¯â•°â•¯â•±â•±â•°â”â”â”â•¯â•±â•°â”â”â”â•¯â•±â•°â”â”â”â•¯â•±â•°â”â”â”â•¯â•±â•°â•¯â•°â•¯â•°â•¯â•±â•°â”â”â”â•¯â•±â•±â•¯â•±\n",
      "\n",
      "\n",
      "24/02/2021, 18:22:46 - \n",
      "\n",
      " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— \n",
      " â•šâ•â•â–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘ \n",
      "   â–ˆâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘ \n",
      "  â–ˆâ–ˆâ–ˆâ•”â•   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•”â•â•â•â•  â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â•   â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ \n",
      " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘ \n",
      " â•šâ•â•â•â•â•â•â•  â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â•â• â•šâ•â•      â•šâ•â• â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â•â• â•šâ•â•     â•šâ•â• \n",
      "\n",
      " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•— \n",
      " â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•— â•šâ•â•â–ˆâ–ˆâ•”â•â•â• â–ˆâ–ˆâ•‘ \n",
      " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘ \n",
      " â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘    â•šâ•â• \n",
      " â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•— \n",
      " â•šâ•â•â•â•â•â•   â•šâ•â•â•â•â•â•     â•šâ•â•    â•šâ•â• \n",
      "\n",
      "\n",
      "24/02/2021, 18:22:46 - \n",
      "function<<<<<authenticating\n",
      "\n",
      "\n",
      "24/02/2021, 18:22:46 - main(): these are the words we're gonna look for: zolpidem, ambien\n",
      "24/02/2021, 18:22:53 - main(): amount of tweets that will be retrieved for every word: 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 193\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import useful_variables\n",
    "import tweepy\n",
    "import time\n",
    "from datetime import date, datetime \n",
    "import os\n",
    "import pymsgbox \n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "from cfonts import render, say\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
