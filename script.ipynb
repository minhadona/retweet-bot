{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    Bot by: @minhadona\n",
    "    First Release: 1 jan 2021 \n",
    "    big text letters font generator: https://fsymbols.com/generators/tarty/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    checking = checks_if_necessary_folders_exist_otherwise_create_them()\n",
    "    checking = checks_if_necessary_files_exist_otherwise_create_them()\n",
    "    if not type(checking) is dict:\n",
    "        logging('checking return: '+str(checking))\n",
    "        raise TypeError('Error: necessary structure cannot be created or validated')\n",
    "        \n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ---------------- populating dictionary with API credentials from json ------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    \n",
    "    with open(useful_variables.credentials_json) as credentials_file:\n",
    "        credentials = json.load(credentials_file)\n",
    "        #logging('credential value: '+ str(credentials))\n",
    "                             \n",
    "    pymsgbox.alert(\"Starting bot!\\n\\n You can monitor what we're doing by reading today's logs on bot_files//logs folder!\", 'Starting bot',timeout=8000)\n",
    "    logging(\"â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘\")\n",
    "    logging(\"â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–‘\")\n",
    "    logging(\"â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•—â–‘\")\n",
    "    logging(\"â–‘â•šâ•â•â•â–ˆâ–ˆâ•—â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â•šâ–ˆâ–ˆâ•—\")\n",
    "    logging(\"â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â•šâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•\")\n",
    "    logging(\"â•šâ•â•â•â•â•â•â–‘â–‘â–‘â–‘â•šâ•â•â–‘â–‘â–‘â•šâ•â•â–‘â–‘â•šâ•â•â•šâ•â•â–‘â–‘â•šâ•â•â–‘â–‘â–‘â•šâ•â•â–‘â–‘â–‘â•šâ•â•â•šâ•â•â–‘â–‘â•šâ•â•â•â–‘â•šâ•â•â•â•â•â•â–‘\")\n",
    "    \n",
    "    try: \n",
    "        api = authenticating(credentials)\n",
    "        \n",
    "        with open(useful_variables.attributes_json) as json_file:\n",
    "            dict_attributes_info = json.load(json_file)\n",
    "            \n",
    "        words = dict_attributes_info[\"words_to_search\"]\n",
    "        liveshow(\"these are the words we're gonna look for:\" +str(words),\"Attributes.json\")\n",
    "\n",
    "        for searched_word in words:\n",
    "\n",
    "            for tweet in tweepy.Cursor(api.search, q = searched_word).items(1100):\n",
    "\n",
    "                dict_tweets_info = {\n",
    "                \"created_at\": [],\n",
    "                \"tweet_ID\": [],\n",
    "                \"user\": [],\n",
    "                \"tweet_content\": [],\n",
    "                \"place\": [],\n",
    "                \"language\": [],\n",
    "                \"source\": [] \n",
    "            }\n",
    "\n",
    "                with open(useful_variables.control_json) as json_file:\n",
    "                    tweets_status = json.load(json_file)\n",
    "                    if tweets_status[\"amount_of_tweets\"] == 999 and tweets_status['current_date'] == date:\n",
    "                        sys.exit('DAILY LIMIT REACHED, CANT RETWEET MORE THAN 1000 TWEETS')\n",
    "\n",
    "                                       \n",
    "                valid_tweet = validate_and_retweet_tweet(api,\n",
    "                                                         tweet,\n",
    "                                                         dict_tweets_info,\n",
    "                                                         dict_attributes_info,\n",
    "                                                         searched_word)\n",
    "\n",
    "                if type(valid_tweet) is dict:\n",
    "                    logging('VALID TWEET !!!!! Ok, we received a dict as return, we may export the results now')\n",
    "                    export_infos_to_csv(valid_tweet)\n",
    "                    write_json_and_updates_value(useful_variables.control_json,incrementa_contagem_de_falha=False)\n",
    "\n",
    "                elif type(valid_tweet) is int:\n",
    "                    logging('Tweet is not valid, analyzing return:: '+str(valid_tweet))\n",
    "                    cases={\n",
    "                        -1 : \"didn't found the searched_word on tweet.text it self\",\n",
    "                        -2 : \"invalid language (japanese, korean, arabic etc problems to recognize the searched word)\",\n",
    "                        -3 : \"you have already retweeted this Tweet\",\n",
    "                        -4 : \"RateLimitError\",\n",
    "                        -5 : \"tweet was made by the bot's account, we can't retweet stuff made by us\",\n",
    "                        -6 : \"tweet is not in desired language\"\n",
    "                    }\n",
    "                    logging(cases.get(valid_tweet,\"Invalid return\"))\n",
    "                    write_json_and_updates_value(useful_variables.control_json,\n",
    "                                                 incrementa_contagem_de_falha=True)\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    logging('Unexpected return for validate_and_retweet_tweet different than dict or int!! content: '+str(valid_tweet) +'type of return: '+str(type(valid_tweet)))\n",
    "                    write_json_and_updates_value(useful_variables.control_json,\n",
    "                                                 incrementa_contagem_de_falha=False)\n",
    "\n",
    "                logging(\"Waiting 2 min to retrieve another tweet cuz we like safety\")\n",
    "                time.sleep(60*2) # sleep 2 min, so we dont reach the limit 100 tweets per hour\n",
    "    \n",
    "    except Exception as error:\n",
    "        if 'status code = 401' in str(error):\n",
    "            logging('INVALID CREDENTIALS, STOPPING BOT')\n",
    "            pymsgbox.alert('INVALID CREDENTIALS on jsoOoooOOooOon!!!', 'Stopping bot',timeout=15000)\n",
    "            want_to_insert_credentials = pymsgbox.confirm('Would you like to insert your credentials here? \\n or... update credentials on \\\\bot_files\\\\controls\\\\credentials.json', 'INSERT CREDENTIALS?', [\"Yes\", \"No, I'll update the json file\"])\n",
    "            if want_to_insert_credentials == 'Yes':\n",
    "                receive_credentials_overwrite_credential_json()\n",
    "                main()\n",
    "        else:\n",
    "            logging('Unkown error:' +str(error))\n",
    "    \n",
    "\n",
    "    logging('â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â€ƒâ€ƒâ–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â€ƒâ€ƒâ–ˆâ–ˆâ•—â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘')\n",
    "    logging('â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â€ƒâ€ƒâ–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â€ƒâ€ƒâ–ˆâ–ˆâ•‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—')\n",
    "    logging('â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â€ƒâ€ƒâ–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â€ƒâ€ƒâ–ˆâ–ˆâ•‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•')\n",
    "    logging('â–ˆâ–ˆâ•”â•â•â•â–‘â–‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â€ƒâ€ƒâ–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–‘â–‘â€ƒâ€ƒâ–ˆâ–ˆâ•‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â–‘')\n",
    "    logging('â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–‘â•šâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â€ƒâ€ƒâ•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–‘â–‘â€ƒâ€ƒâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–‘â–‘')\n",
    "    logging('â•šâ•â•â•â•â•â•â•â•šâ•â•â–‘â–‘â•šâ•â•â•â•šâ•â•â•â•â•â•â–‘â€ƒâ€ƒâ–‘â•šâ•â•â•â•â•â–‘â•šâ•â•â–‘â–‘â–‘â–‘â–‘â€ƒâ€ƒâ•šâ•â•â•â•â•â•â•â•šâ•â•â–‘â–‘â•šâ•â•â•šâ•â•â–‘â–‘â–‘â–‘â–‘')\n",
    "    \n",
    "    pymsgbox.alert('$$$$$$$$$$$$$$ \\n END OF LAP\\n $$$$$$$$$$$$$', 'End of times',timeout=40000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticating(credential):\n",
    "    logging('\\n\\nfunction>>>>>authenticating')\n",
    "     \n",
    "    \"\"\"   \n",
    "    â–ˆâ€ƒâ–ˆâ–„â–‘â–ˆ\n",
    "    â–ˆâ€ƒâ–ˆâ–‘â–€â–ˆ    \n",
    "    \"\"\"\n",
    "        # credential         â€¢ <dictionary>                 â—‹ its keys will be used to authenticate\n",
    "        \n",
    "    \"\"\"\n",
    "    â–ˆâ–€â–ˆâ€ƒâ–ˆâ–‘â–ˆâ€ƒâ–€â–ˆâ–€\n",
    "    â–ˆâ–„â–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–‘â–ˆâ–‘\n",
    "    \"\"\"\n",
    "        # api                â€¢ <class 'tweepy.api.API'>     â—‹ authenticated api\n",
    "   \n",
    "    auth = tweepy.OAuthHandler(credential[\"api_key\"], credential[\"api_secret\"])\n",
    "    auth.set_access_token(credential[\"access_token\"], credential[\"access_token_secret\"])\n",
    "\n",
    "    api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    \n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_retweet_tweet(api, tweet, dict_tweets_info, dict_attributes_info, searched_word):\n",
    "    logging('\\n\\nfunction>>>>>validate_and_retweet_tweet')\n",
    "    \n",
    "    \"\"\"   \n",
    "    â–ˆâ€ƒâ–ˆâ–„â–‘â–ˆ\n",
    "    â–ˆâ€ƒâ–ˆâ–‘â–€â–ˆ    \n",
    "    \"\"\"\n",
    "        # api                â€¢ <class 'tweepy.api.API'>    â—‹ authenticated api\n",
    "        # tweet              â€¢ <tweet object>              â—‹ one single tweet object and its attributes \n",
    "        # dict_tweets_info   â€¢ <dictionary>                â—‹ empty, to be filled with informations from this tweet object\n",
    "        # searched_word      â€¢ <string>                    â—‹ seeking term (will be used here to validate the inner content of the tweet) \n",
    "    \n",
    "    \"\"\"\n",
    "    â–ˆâ–€â–ˆâ€ƒâ–ˆâ–‘â–ˆâ€ƒâ–€â–ˆâ–€\n",
    "    â–ˆâ–„â–ˆâ€ƒâ–ˆâ–„â–ˆâ€ƒâ–‘â–ˆâ–‘\n",
    "    \"\"\"\n",
    "        # -1           â—‹ didn't found the searched_word on tweet.text it self \n",
    "        # -2           â—‹ forbidden language (japanese, korean, arabic etc problems to recognize the searched word)\n",
    "        # -3           â—‹ you have already retweeted this Tweet\n",
    "        # -4           â—‹ RateLimitError\n",
    "        # -5           â—‹ tweet was made by the bot's account, we can't retweet stuff made by us \n",
    "        # -6           â—‹ tweet is not in aimed language\n",
    "        # -7           â—‹ tweet made by a forbidden-to-retweet user\n",
    "        # dict         â—‹ in a valid situation, returns a populated dictionary containing this tweet's data \n",
    "\n",
    "    try: \n",
    "\n",
    "        logging('appending infos retrieved to dictionary')\n",
    "        dict_tweets_info['created_at'].append(str(tweet.created_at))\n",
    "        dict_tweets_info['tweet_ID'].append(str(tweet.id))\n",
    "        dict_tweets_info['user'].append(str(tweet.user.screen_name))\n",
    "        dict_tweets_info['tweet_content'].append((tweet.text))\n",
    "        dict_tweets_info['place'].append(str(tweet.place))\n",
    "        dict_tweets_info['language'].append(str(tweet.lang))\n",
    "        dict_tweets_info['source'].append(str(tweet.source_url).replace(\"http://twitter.com/download/\",\"\"))\n",
    "    \n",
    "        logging('----------------------------------------')\n",
    "        logging('raw dict_tweets_info after appending: \\n '+str(dict_tweets_info))\n",
    "        logging('----------------------------------------')\n",
    "        \n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    # --------------------------------- FILTERING BEFORE RETWEET ----------------------------------------------\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        logging('validate_and_retweet_tweet(): better filtering BEFORE retweet')\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        string_lang_content = \"\".join(dict_tweets_info['language'] )  # ð­ð®ð«ð§ð¬ ð¥ð¢ð¬ð­ ð¢ð§ð­ð¨ ð¬ð­ð«ð¢ð§ð  ð­ð¨ ðœð¨ð¦ð©ðšð«ðž\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------- checking if it's in one of the ENFORCED languages ----------------------\n",
    "        # -----------------------------------------------------------------------------------------------------        \n",
    "        logging('filtering :::: enforced languages')\n",
    "        if dict_attributes_info[\"restrict_tweets_to_these_languages\"]:\n",
    "            # only comes here if list is not empty! we have to enforce the languages on the list\n",
    "            logging('these are the current enforced languages: '+str(dict_attributes_info[\"restrict_tweets_to_these_languages\"]))\n",
    "            if not string_lang_content in dict_attributes_info[\"restrict_tweets_to_these_languages\"]:\n",
    "                logging('ENFORCED LANG not OK: this tweet is not in enforced languages list, we wont retweet any other language!')\n",
    "                return -6\n",
    "            else: \n",
    "                logging('ENFORCED LANG OK: this tweet is allowed by the enforced languages list: '+string_lang_content)        \n",
    "        else:\n",
    "            logging('ENFORCED LANG OK: RESTRICTION LIST IS EMPTY, WE DONT NEED TO ENFORCE ANY LANGUAGE')\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------- checking if it's in one of the FORBIDDEN languages ---------------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        logging('filtering :::: forbidden languages')\n",
    "        if string_lang_content in dict_attributes_info[\"forbidden_languages_to_retweet\"]:\n",
    "            logging('FORBIDDEN LANG not OK: dumb robot, tweet is not in an understandable language so its content will be wrongly evaluated, we stop here')\n",
    "            return -2\n",
    "        else: \n",
    "            logging('FORBIDDEN LANG OK: tweet is not in any forbidden language! language is actually: '+string_lang_content)\n",
    "            \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------- checking if the searched word really is on tweet content ---------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        logging('filtering :::: searched word on tweet text')\n",
    "        string_tweet_content = \"\".join(dict_tweets_info['tweet_content'] ) # turns list into string to compare\n",
    "        if not searched_word in string_tweet_content.lower():\n",
    "            logging('SEARCHED WORD not OK: we havent found '+ searched_word + ' on tweet content')\n",
    "            # NO WAY it's gonna retweet something that has NOT the word on the text\n",
    "            return -1\n",
    "        else:\n",
    "            logging('SEARCHED WORD OK: we found the searched word on tweet content!')\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        user_of_this_tweet = str(tweet.user.screen_name)   # ð­ð®ð«ð§ð¬ ð¬ðœð«ðžðžð§_ð§ðšð¦ðž ðšð­ð­ð«ð¢ð›ð®ð­ðž ð¢ð§ð­ð¨ ð¬ð­ð«ð¢ð§ð  ð­ð¨ ðœð¨ð¦ð©ðšð«ðž\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ------------------------- checking if this tweet's user is among the forbidden users ---------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        logging('filtering :::: forbidden users')\n",
    "        if dict_attributes_info[\"users_to_not_retweet\"]:\n",
    "            # only comes here if list is not empty! we have to block retweets from these users on list\n",
    "            logging('these are the current forbidden users to retweet: '+ str(dict_attributes_info[\"users_to_not_retweet\"]))\n",
    "            if str(tweet.user.screen_name) in dict_attributes_info[\"users_to_not_retweet\"]:\n",
    "                logging('FORBIDDEN USERS not OK: this tweet was made by a forbidden-to-retweet user')\n",
    "                return -7\n",
    "            else: \n",
    "                logging('FORBIDDEN USERS OK: we are allowed to retweet tweets from @'+ user_of_this_tweet)        \n",
    "        else:\n",
    "            logging('FORBIDDEN USERS OK: LIST IS EMPTY, WE DONT NEED TO IGNORE ANY USER')\n",
    "        \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ------------------------- checking if this tweet's user is also the authenticated user --------------\n",
    "        # -------------------------------- (so we dont retweet our ð¨ð°ð§ tweets) --------------------------------\n",
    "        logging(\"filtering :::: tweet's user vs authenticated one\")\n",
    "        my_user_object = api.me()\n",
    "        if str(my_user_object.screen_name) == user_of_this_tweet:\n",
    "            logging('you are @'+ str(my_user_object.screen_name))\n",
    "            logging('OWN AUTHORSHIP not OK: this tweet was made by yourself using your bot profile or is an old RETWEET!! both cases we wont retweet it again')\n",
    "            return -5\n",
    "        else:\n",
    "            logging('OWN AUTHORSHIP OK: this user is not you! you: '+ str(my_user_object.screen_name) + ' VS this user: '+ user_of_this_tweet +', that s great')\n",
    "        \n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    # ---------------------------------- RETWEET ACTION ! -----------------------------------------------------\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        logging('retweeting â†â†â†â†â†â†â†â†â†â†â†â†â†')\n",
    "        api.retweet(tweet.id)\n",
    "        logging('â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’ retweeted') # if an exception is raised during retweet method, we wont arrive here\n",
    "        return dict_tweets_info\n",
    "    \n",
    "    except tweepy.TweepError as e: \n",
    "        if e.api_code == 327:\n",
    "            logging('Exception Code 327: You have already retweeted this Tweet')\n",
    "            return -3\n",
    "        \n",
    "    except tweepy.RateLimitError as e:\n",
    "        logging('RateLimitError')\n",
    "        logging('Unknown error: '+str(e))\n",
    "        logging('according to internet, sleeping for 15 min should solve...')\n",
    "        time.sleep(60 * 15)  # we saw rate limit is ignored after 15 min ??? ///not confirmed hypothesis///\n",
    "        return -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_and_updates_value(path, incrementa_contagem_de_falha=False, inicializar = False):\n",
    "    logging('\\n\\nfunction>>>>>write_json_and_updates_value')\n",
    "    \n",
    "    \"\"\"   \n",
    "    â–ˆâ€ƒâ–ˆâ–„â–‘â–ˆ\n",
    "    â–ˆâ€ƒâ–ˆâ–‘â–€â–ˆ    \n",
    "    \"\"\"\n",
    "        # path                           â€¢ <string>          â—‹ control json path\n",
    "        # incrementa_contagem_de_falha   â€¢ <bool>            â—‹ boolean flag to update or not a specific key\n",
    "        # inicializar                    â€¢ <bool>            â—‹ boolean flag to reset (set to 0) or not all the keys\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_date = now.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    # try to read from file\n",
    "    try:\n",
    "        with open(path) as json_file:\n",
    "            tweets_status = json.load(json_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "    # write on file\n",
    "    # if our current date is the same, increase amount of tweets.\n",
    "    # if our current date is different, amount is ZERO !!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "    if inicializar or tweets_status['current_date'] != current_date: \n",
    "        logging('different dates, OR initializing, so we need to change the current_date value and also turn into 0 all the values')\n",
    "        with open(path, 'w') as f:\n",
    "            try:\n",
    "                content = {\"current_date\": current_date,\n",
    "                           \"amount_of_tweets\": 0,\n",
    "                           \"total_amount_including_failure\":0}\n",
    "                json.dump(content, f)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging('decode error but will try raw writing')\n",
    "                f.write(contenting)\n",
    "    else: \n",
    "        logging('same date!! so, just change the value of tweetts')\n",
    "        if not incrementa_contagem_de_falha:\n",
    "                logging('increases both keys , the including failure and the sucessed amounts')\n",
    "                #vai incrementtar o total com falhas tb + o total dos sucessos\n",
    "                tweets_status[\"amount_of_tweets\"] = tweets_status[\"amount_of_tweets\"]+1 \n",
    "                tweets_status['total_amount_including_failure'] = tweets_status['total_amount_including_failure']+1\n",
    "                with open(path, 'w') as f:\n",
    "                    try:\n",
    "                        json.dump(tweets_status, f)\n",
    "                    except json.JSONDecodeError:\n",
    "                        logging('decode error but will try raw writing')\n",
    "                        f.write(contenting)\n",
    "                    \n",
    "        elif incrementa_contagem_de_falha:\n",
    "                # vai incrementar SOMENTE chave com total de tweets, independente de ter falhado ou nao\n",
    "                logging('INCREMENTANDO CHAVE DE CONTAGEM TOTAL DE TWEETS')\n",
    "                     # increasing amount of the ones who failure \n",
    "                tweets_status['total_amount_including_failure'] = tweets_status['total_amount_including_failure']+1\n",
    "\n",
    "                with open(path, 'w') as f:\n",
    "                    try:\n",
    "                        json.dump(tweets_status, f)\n",
    "\n",
    "                    except json.JSONDecodeError:\n",
    "                        logging('decode error but will try raw writing')\n",
    "                        f.write(contenting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_infos_to_csv(valid_tweet):\n",
    "    logging('\\n\\nfunction>>>>>exporting_infos_to_csv')\n",
    "        \n",
    "    \"\"\"   \n",
    "    â–ˆâ€ƒâ–ˆâ–„â–‘â–ˆ\n",
    "    â–ˆâ€ƒâ–ˆâ–‘â–€â–ˆ    \n",
    "    \"\"\"\n",
    "        # valid tweet        â€¢ <dictionary>          â—‹ dictionary holding all informations we retrieved from one specific tweet\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # ------------------------- fetch today's DATE in DD/MM/YYY format and turns into DD-MM-YYYY ------------------\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%d/%m/%Y\").replace(\"/\",\"-\").replace(':',\"-\").replace(',','--').replace(\" \",\"\")\n",
    "\n",
    "    CSV_path = useful_variables.exported_data_folder+'\\\\dados_'+timestamp+'.csv'\n",
    "    logging(\"today's CSV path: \"+str(CSV_path))\n",
    "\n",
    "    logging('valid_tweet : '+str(valid_tweet))\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    # -------- to exclusively append tweet's informations, we CANT append dict directly, otherwise the function ---\n",
    "    # ------------- will append header (dict keys) row + informations (dict values) row for EVERY tweet -----------\n",
    "    # --------- so we turn the dict values into a list and we only append header if it's a new CSV (new day) ------\n",
    "    # -------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        # ---------------------------------- turning dict values into a list ----------------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    dict_values_in_list_version = []\n",
    "    for key, value in valid_tweet.items():\n",
    "        dict_values_in_list_version.append(\"\".join(value))\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        # -------- forcing Tweet ID to be written as string on sheet, so it doesnt truncate as scientific notation --\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    dict_values_in_list_version[1] = '\\''+dict_values_in_list_version[1]\n",
    "\n",
    "    logging('dict_values_in_list_version: '+str(dict_values_in_list_version))\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "        # --------- if today's CSV already exists, we will append only this specific tweet's DETAILS to file --------\n",
    "        # ----------------- elseways we append the header (creating a new file) -------------------------------------\n",
    "        # ------------------- and THEN append current tweet's details normally --------------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    if not os.path.exists(CSV_path):\n",
    "        logging('today s csv does not exist yet, creating it and appending header')\n",
    "        header_csv = ['created_at','tweet_ID','user','tweet_content','place','language','source'] \n",
    "        with open(CSV_path, \"a\", encoding=\"utf-8\", newline='') as file:\n",
    "            wr = csv.writer(file)\n",
    "            wr.writerow(header_csv)\n",
    "            \n",
    "    with open(CSV_path, \"a\", encoding=\"utf-8\", newline='') as file:\n",
    "        logging('writing tweet details on CSV file')\n",
    "        wr = csv.writer(file)\n",
    "        wr.writerow(dict_values_in_list_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(text_to_log=\"\"):\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "    # ------------------- converts into string the parameter we want to write on log file -----------------------\n",
    "    # ------------------------- just in case we received another variable type ----------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    text_to_log = str(text_to_log)\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "    # --------------------------- fetchs timestamp to append within received text -------------------------------\n",
    "    # ---------- fetchs current date to create new log file or append to the current one ------------------------\n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    now = datetime.now()\n",
    "    date = now.strftime(\"%d/%m/%Y\").replace(\"/\",\"-\")\n",
    "    timestamp = now.strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
    "\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ---- retrieves directory where our robot is running and concatenate the path to the current day's ---\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    log_path = useful_variables.logs_folder+'\\\\log_'+date+'.txt'\n",
    "    \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ----- appending to file of the day: timestamp + parameter's content ---------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "    with open(log_path, 'a+',encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(timestamp+ ' - ' + text_to_log+'\\n')\n",
    "    \n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "        # ------ printing on console ----------------------------------------------------------------------------\n",
    "        # -----------------------------------------------------------------------------------------------------\n",
    "    print(timestamp+ ' - ' + text_to_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_special_text_to_ascii(original_text):\n",
    "    translated_text = ''\n",
    "\n",
    "    for character in original_text:\n",
    "        if ord(character) >= 128:\n",
    "            translated_text = translated_text + '\"Chr(' + str(ord(character)) + ')\"'\n",
    "        else:\n",
    "            translated_text = translated_text + character\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_credentials_overwrite_credential_json():                \n",
    "    logging('\\n\\nfunction>>>>>receive_credentials_overwrite_credential_json')\n",
    "    \n",
    "    new_api_key = pymsgbox.prompt('Insert your API KEY', default='3x4mPL3-j13j2o38s09dsaf')\n",
    "    new_api_secret = pymsgbox.prompt('Insert your API SECRET', default='3x4mPL3-j13j2o38s09dsaf')\n",
    "    new_bearer_token = pymsgbox.prompt('Insert your BEARER TOKEN', default='3x4mPL3-j13j2o38s09dsaf')\n",
    "    new_access_token = pymsgbox.prompt('Insert your ACCESS TOKEN', default='3x4mPL3-j13j2o38s09dsaf')\n",
    "    new_access_token_secret = pymsgbox.prompt('Insert your ACCESS TOKEN SECRET', default='3x4mPL3-j13j2o38s09dsaf')\n",
    " \n",
    "    with open(useful_variables.credentials_json, 'w') as f:\n",
    "        try:\n",
    "            content = {\"api_key\" : new_api_key,\n",
    "                       \"api_secret\" : new_api_secret,\n",
    "                       \"bearer_token\" : new_bearer_token,\n",
    "                       \"access_token\" : new_access_token,\n",
    "                       \"access_token_secret\" : new_access_token_secret}\n",
    "            json.dump(content, f)\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            logging('decode error but will try raw writing')\n",
    "            f.write(contenting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liveshow(text=\"\",title=\"Are we on air?\",timeout=5000):\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # live show Definition (n.): \n",
    "    #        \"ð“ð’¾ð“‹ð‘’ ð’·ð“‡ð‘œð’¶ð’¹ð’¸ð’¶ð“ˆð“‰, ð’·ð“‡ð‘œð’¶ð’¹ð’¸ð’¶ð“ˆð“‰ ð“‰ð’½ð’¶ð“‰ ð’¾ð“ˆ ð’¶ð’¾ð“‡ð‘’ð’¹ ð’¾ð“ƒ ð“‡ð‘’ð’¶ð“-ð“‰ð’¾ð“‚ð‘’ \" \n",
    "    #                          https://www.dictionarist.com/live+show\n",
    "    # ----------------------------------------------------------------\n",
    "\n",
    "    logging(text)\n",
    "    pymsgbox.alert(text = text,\n",
    "                  title = title,\n",
    "                  timeout = timeout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checks_if_necessary_folders_exist_otherwise_create_them():\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # ---------------------  CREATES INTO SCRIPT DIRECTORY ALL NECESSARY FOLDERS  ------------------\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    try:\n",
    "        if not os.path.exists(useful_variables.logs_folder):\n",
    "            pymsgbox.alert(text=\"Creating logs' folder\", title='Setting bot up', button='OK',timeout=4500)\n",
    "            os.makedirs(useful_variables.logs_folder)\n",
    "            logging(\"Creating logs' folder\")\n",
    "        else:\n",
    "            liveshow(str(useful_variables.logs_folder) + ' already exists')\n",
    "\n",
    "        if not os.path.exists(useful_variables.controls_folder):\n",
    "            pymsgbox.alert(text='Creating controls folder', title='Setting bot up', button='OK',timeout=4500)\n",
    "            os.makedirs(useful_variables.controls_folder)\n",
    "            logging(\"Creating controls folder\")\n",
    "        else:\n",
    "            liveshow(str(useful_variables.controls_folder) + ' already exists')\n",
    "\n",
    "        if not os.path.exists(useful_variables.exported_data_folder):\n",
    "            pymsgbox.alert(text='Creating exported_data folder', title='Setting bot up', button='OK',timeout=4500)\n",
    "            os.makedirs(useful_variables.exported_data_folder)\n",
    "            logging(\"Creating exported_data folder\")\n",
    "        else:\n",
    "            liveshow(str(useful_variables.exported_data_folder) + ' already exists')\n",
    "    \n",
    "    except Exception as error:\n",
    "        logging('Unknown error: '+str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checks_if_necessary_files_exist_otherwise_create_them():\n",
    "    logging('\\n\\nfunction>>>>>checks_if_necessary_files_exist_otherwise_create_them')\n",
    "    \n",
    "    # -1    invalid attributes: some value on attributes dict is not list type ('a' :   ['LIST','LIST'])\n",
    "    # -2    invalid attributes: exclude a language from retweeting and ask to retweet the same language is contraditory\n",
    "    # dict  success to create and validate all json files\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    # ---------- checking if control json exists, otherwise we create it -------------------\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    control_json = useful_variables.control_json\n",
    "    if not os.path.exists(control_json):\n",
    "        logging(\"control json not found, gotta create it\")\n",
    "        write_json_and_updates_value(control_json,\n",
    "                                     incrementa_contagem_de_falha = False,\n",
    "                                     inicializar = True)\n",
    "    else:\n",
    "        logging(str(control_json) + ' already exists')\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------    \n",
    "    # ---------- checking if credentials json exists, otherwise we create it -------------------\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    \n",
    "    credentials_json = useful_variables.credentials_json\n",
    "    if not os.path.exists(credentials_json):\n",
    "        logging(\"credentials json not found, gotta create it using a template\")\n",
    "        \n",
    "        with open(credentials_json, 'w') as f:\n",
    "            try:\n",
    "                content_template = {\"api_key\" : \"examplen9masss23423553252ffffffe\",\n",
    "                           \"api_secret\" : \"examplefa1asfsafsafsa32434fdfsfsdfddsfsfddfdfsfd\",\n",
    "                           \"bearer_token\" : \"exampleAAAAAAAAAADFDSFGDDGGDAGDFHDFHBV424G4023fe032402320F242WER355W31tg21e454F4E4ER4Esfdsdfdfs\",\n",
    "                           \"access_token\" : \"example13371788gfdfgdfgdfgd344544gdfgfdsj5jytjjy\",\n",
    "                           \"access_token_secret\" : \"examplect42gdfhf5y66hsvbbgfhC91Rhfghgf45t4555552432324235\"}\n",
    "                json.dump(content_template, f)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging('decode error but will try raw writing')\n",
    "                f.write(content_template)\n",
    "                \n",
    "    else:\n",
    "        logging(str(credentials_json) + ' already exists')\n",
    "        \n",
    "    # ------------------------------------------------------------------------------------------    \n",
    "    # ---------- checking if attributes json exists, otherwise we create it --------------------\n",
    "    # ------------------------------------------------------------------------------------------\n",
    "    \n",
    "    attributes_json = useful_variables.attributes_json\n",
    "    \n",
    "    content_template = {\"words_to_search\" : ['zolpidem','ambien'],\n",
    "                           \"users_to_not_retweet\" : ['user1','user2'],\n",
    "                           \"forbidden_languages_to_retweet\" : ['ja','ko','und','fa','ar'],\n",
    "                           \"restrict_tweets_to_these_languages\" : [] }\n",
    "    \n",
    "    if not os.path.exists(attributes_json):\n",
    "        logging(\"credentials json not found, gotta create it using a valid template\")\n",
    "        \n",
    "        with open(attributes_json, 'w') as f:\n",
    "            try:\n",
    "                \n",
    "                json.dump(content_template, f)\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                logging('decode error but will try raw writing')\n",
    "                f.write(contenting)\n",
    "                \n",
    "            finally:\n",
    "                return content_template\n",
    "                \n",
    "    else:\n",
    "        # -------------------------------------------------------------------------------------\n",
    "        # ---------------- if file exists already, we will validate any inconsistency ---------\n",
    "        # -------------------------------------------------------------------------------------\n",
    "        \n",
    "        logging(str(attributes_json) + ' already exists, let s validate the dictionary')\n",
    "        with open(useful_variables.attributes_json) as json_file:\n",
    "            dict_attributes_info = json.load(json_file)\n",
    "            \n",
    "            # ----------- all values have to be LIST type -----------------------\n",
    "            \n",
    "            for key, value in dict_attributes_info.items():\n",
    "                if not type(value) is list:\n",
    "                    liveshow('YOU VE CHANGED THE TYPE OF SOME VALUE ON JSON! \\nPLEASE, DELETE THE FILE, restart the bot AND FOLLOW THE INITIAL TEMPLATE we will create! \\nALL VALUES HAVE TO BE LIST TYPE! \\n\\nfile is on \\\\bot_files\\\\controls\\\\attributes.json', 'BOT CANNOT START WITH INVALID ATTRIBUTES')\n",
    "                    return -1\n",
    "            \n",
    "            # ----------- cant have same value on _restrict and _forbiden -------\n",
    "            \n",
    "            for language in dict_attributes_info['restrict_tweets_to_these_languages']:\n",
    "                if language in dict_attributes_info['forbidden_languages_to_retweet']:\n",
    "                    liveshow('you cant ask us to only retweet things in the same language you WANT TO PROHIBIT retweeting! \\nPLEASE UPDATE JSON FILE ON \\\\bot_files\\\\controls\\\\attributes.json and try again','what?')\n",
    "                    return -2\n",
    "                \n",
    "            # ----------- cant have empty value on words_to_search -------------\n",
    "            \n",
    "            if not dict_attributes_info[\"words_to_search\"]:\n",
    "                liveshow(\"THIS IS A RETWEET BOT, if we have no words to look for, what do you want us to do? \\nPlease update attributes.json inside of CONTROLS folder and set a list of words\",\"Oh no\",8000)\n",
    "                return -3\n",
    "                \n",
    "        return content_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/01/2021, 13:37:51 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\logs already exists\n",
      "15/01/2021, 13:37:57 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\controls already exists\n",
      "15/01/2021, 13:38:02 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\exported_data already exists\n",
      "15/01/2021, 13:38:07 - \n",
      "\n",
      "function>>>>>checks_if_necessary_files_exist_otherwise_create_them\n",
      "15/01/2021, 13:38:07 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\controls\\amount_of_tweets_from_today.json already exists\n",
      "15/01/2021, 13:38:07 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\controls\\credentials.json already exists\n",
      "15/01/2021, 13:38:07 - C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\controls\\attributes.json already exists, let s validate the dictionary\n",
      "15/01/2021, 13:38:12 - â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘\n",
      "15/01/2021, 13:38:12 - â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–‘\n",
      "15/01/2021, 13:38:12 - â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•—â–‘\n",
      "15/01/2021, 13:38:12 - â–‘â•šâ•â•â•â–ˆâ–ˆâ•—â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â•šâ–ˆâ–ˆâ•—\n",
      "15/01/2021, 13:38:12 - â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â•šâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•\n",
      "15/01/2021, 13:38:12 - â•šâ•â•â•â•â•â•â–‘â–‘â–‘â–‘â•šâ•â•â–‘â–‘â–‘â•šâ•â•â–‘â–‘â•šâ•â•â•šâ•â•â–‘â–‘â•šâ•â•â–‘â–‘â–‘â•šâ•â•â–‘â–‘â–‘â•šâ•â•â•šâ•â•â–‘â–‘â•šâ•â•â•â–‘â•šâ•â•â•â•â•â•â–‘\n",
      "15/01/2021, 13:38:12 - \n",
      "\n",
      "function>>>>>authenticating\n",
      "15/01/2021, 13:38:12 - these are the words we're gonna look for:['zolpidem', 'ambien']\n",
      "15/01/2021, 13:38:18 - \n",
      "\n",
      "function>>>>>validate_and_retweet_tweet\n",
      "15/01/2021, 13:38:18 - appending infos retrieved to dictionary\n",
      "15/01/2021, 13:38:18 - ----------------------------------------\n",
      "15/01/2021, 13:38:18 - raw dict_tweets_info after appending: \n",
      " {'created_at': ['2021-01-15 16:32:43'], 'tweet_ID': ['1350118729590468609'], 'user': ['davieamaquina'], 'tweet_content': ['@gnomopotter depende da farmÃ¡cia, mas zolpidem geralmente dÃ¡, ou vc pode fazer uso de cannabinoide q tem efeito semelhante kkkkk'], 'place': ['None'], 'language': ['pt'], 'source': ['android']}\n",
      "15/01/2021, 13:38:18 - ----------------------------------------\n",
      "15/01/2021, 13:38:18 - validate_and_retweet_tweet(): better filtering BEFORE retweet\n",
      "15/01/2021, 13:38:18 - filtering :::: enforced languages\n",
      "15/01/2021, 13:38:18 - ENFORCED LANG OK: RESTRICTION LIST IS EMPTY, WE DONT NEED TO ENFORCE ANY LANGUAGE\n",
      "15/01/2021, 13:38:18 - filtering :::: forbidden languages\n",
      "15/01/2021, 13:38:18 - FORBIDDEN LANG OK: tweet is not in any forbidden language! language is actually: pt\n",
      "15/01/2021, 13:38:18 - filtering :::: searched word on tweet text\n",
      "15/01/2021, 13:38:18 - SEARCHED WORD OK: we found the searched word on tweet content!\n",
      "15/01/2021, 13:38:18 - filtering :::: forbidden users\n",
      "15/01/2021, 13:38:18 - these are the current forbidden users to retweet: ['user1', 'user2']\n",
      "15/01/2021, 13:38:18 - FORBIDDEN USERS OK: we are allowed to retweet tweets from @davieamaquina\n",
      "15/01/2021, 13:38:18 - filtering :::: tweet's user vs authenticated one\n",
      "15/01/2021, 13:38:18 - OWN AUTHORSHIP OK: this user is not you! you: zolpidembot VS this user: davieamaquina, that s great\n",
      "15/01/2021, 13:38:18 - retweeting â†â†â†â†â†â†â†â†â†â†â†â†â†\n",
      "15/01/2021, 13:38:19 - â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’â†’ retweeted\n",
      "15/01/2021, 13:38:19 - VALID TWEET !!!!! Ok, we received a dict as return, we may export the results now\n",
      "15/01/2021, 13:38:19 - \n",
      "\n",
      "function>>>>>exporting_infos_to_csv\n",
      "15/01/2021, 13:38:19 - today's CSV path: C:\\Users\\gabri\\Documents\\retweet-bot\\bot_files\\exported_data\\dados_15-01-2021.csv\n",
      "15/01/2021, 13:38:19 - valid_tweet : {'created_at': ['2021-01-15 16:32:43'], 'tweet_ID': ['1350118729590468609'], 'user': ['davieamaquina'], 'tweet_content': ['@gnomopotter depende da farmÃ¡cia, mas zolpidem geralmente dÃ¡, ou vc pode fazer uso de cannabinoide q tem efeito semelhante kkkkk'], 'place': ['None'], 'language': ['pt'], 'source': ['android']}\n",
      "15/01/2021, 13:38:19 - dict_values_in_list_version: ['2021-01-15 16:32:43', \"'1350118729590468609\", 'davieamaquina', '@gnomopotter depende da farmÃ¡cia, mas zolpidem geralmente dÃ¡, ou vc pode fazer uso de cannabinoide q tem efeito semelhante kkkkk', 'None', 'pt', 'android']\n",
      "15/01/2021, 13:38:19 - writing tweet details on CSV file\n",
      "15/01/2021, 13:38:19 - \n",
      "\n",
      "function>>>>>write_json_and_updates_value\n",
      "15/01/2021, 13:38:19 - same date!! so, just change the value of tweetts\n",
      "15/01/2021, 13:38:19 - increases both keys , the including failure and the sucessed amounts\n",
      "15/01/2021, 13:38:19 - Waiting 2 min to retrieve another tweet cuz we like safety\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-65b6967f35b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-58b24b33ac06>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Waiting 2 min to retrieve another tweet cuz we like safety\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sleep 2 min, so we dont reach the limit 100 tweets per hour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import useful_variables\n",
    "import tweepy\n",
    "import time\n",
    "from datetime import date, datetime \n",
    "import os\n",
    "import pymsgbox \n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
